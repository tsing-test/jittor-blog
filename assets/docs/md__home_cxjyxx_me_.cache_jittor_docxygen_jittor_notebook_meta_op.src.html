<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Jittor: Meta-operator: Implement your own convolution with Meta-operator</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Jittor
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Meta-operator: Implement your own convolution with Meta-operator </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Meta-operator is a key concept of jittor, The hierarchical architecture of meta-operators is shown below.</p>
<p>The meta-operators are consist of reindex, reindex-reduce and element-wise operators. Reindex and reindex-reduce operators are both unary operators. The reindex operator is a one-to-many mapping between its input and output. And the reindex-reduce operator is a many-to-one mapping. Broadcast, pad and slice operators are common reindex operators. And reduce, product and sum are common reindex-reduce operators. Element-wise operator is the third component of meta-operators. Compared to the first two, element-wise operators may contain multiple inputs. But all the input and output shapes of C must be the same. And they are one-to-one mapped. For example, the addition of two variables is a binary element-wise operator. </p><blockquote class="doxtable">
<div class="image">
<img src="./figs/mop.svg" />
</div>
<p> The hierarchical architecture of meta-operators. The meta-operators are consist of reindex, reindex-reduce and element-wise operators. Reindex and reindex-reduce are each other's backward operators. The backward operators of element-wise operators are itself. Those meta-operators are fused into common DL operations, and these DL operators further constitute the model. </p>
</blockquote>
<p>In the previous <a href="example.ipynb">example</a>, we have demonstrated how to implement matrix multiplication via three meta-operators:</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;def matmul(a, b):</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;    (n, m), k = a.shape, b.shape[-1]</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;    a = a.broadcast([n,m,k], dims=[2])</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;    b = b.broadcast([n,m,k], dims=[0])</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;    return (a*b).sum(dim=1)</div></div><!-- fragment --><p>In this tutorial, we will show how to implement your own convolution with meta-operator.</p>
<p>First, let's implement a naive Python convolution:</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;import numpy as np</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;import os</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;def conv_naive(x, w):</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;    N,H,W,C = x.shape</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;    Kh, Kw, _C, Kc = w.shape</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;    assert C==_C, (x.shape, w.shape)</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;    y = np.zeros([N,H-Kh+1,W-Kw+1,Kc])</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;    for i0 in range(N):</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;        for i1 in range(H-Kh+1): # dimension error</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;            for i2 in range(W-Kw+1):</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;                for i3 in range(Kh):</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;                    for i4 in range(Kw):</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;                        for i5 in range(C):</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;                            for i6 in range(Kc):</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;                                if i1-i3&lt;0 or i2-i4&lt;0 or i1-i3&gt;=H or i2-i4&gt;=W: continue</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;                                y[i0, i1, i2, i6] += x[i0, i1 + i3, i2 + i4, i5] * w[i3,i4,i5,i6]</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;    return y</div></div><!-- fragment --><p>Then, let's download a cat image, and run <code>conv_naive</code> with a simple horizontal filter</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;# %matplotlib inline</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;import pylab as pl</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;img_path=&quot;/tmp/cat.jpg&quot;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;if not os.path.isfile(img_path):</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;    !wget -O - &#39;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Felis_silvestris_catus_lying_on_rice_straw.jpg/220px-Felis_silvestris_catus_lying_on_rice_straw.jpg&#39; &gt; $img_path</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;img = pl.imread(img_path)</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;pl.subplot(121)</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;pl.imshow(img)</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;kernel = np.array([</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;    [-1, -1, -1],</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;    [0, 0, 0],</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;    [1, 1, 1],</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;])</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;pl.subplot(122)</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;x = img[np.newaxis,:,:,:1].astype(&quot;float32&quot;)</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;w = kernel[:,:,np.newaxis,np.newaxis].astype(&quot;float32&quot;)</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;y = conv_naive(x, w)</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;print (x.shape, y.shape) # shape exists confusion</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;pl.imshow(y[0,:,:,0])</div></div><!-- fragment --><p> It looks good, our <code>naive_conv</code> works well. Let's replace our naive implementation with jittor</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;import jittor as jt</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;def conv(x, w):</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;    N,H,W,C = x.shape</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;    Kh, Kw, _C, Kc = w.shape</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;    assert C==_C</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;    xx = x.reindex([N,H-Kh+1,W-Kw+1,Kh,Kw,C,Kc], [</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;        &#39;i0&#39;, # Nid</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;        &#39;i1+i3&#39;, # Hid+Khid</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;        &#39;i2+i4&#39;, # Wid+KWid</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;        &#39;i5&#39;, # Cid|</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;    ])</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;    ww = w.broadcast_var(xx)</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;    yy = xx*ww</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;    y = yy.sum([3,4,5]) # Kh, Kw, Kc</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;    return y</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;# Let&#39;s disable tuner. This will cause jittor not to use mkl for convolution</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;jt.flags.enable_tuner = 0</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;jx = jt.array(x)</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;jw = jt.array(w)</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;jy = conv(jx, jw).fetch_sync()</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;print (jx.shape, jy.shape)</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;pl.imshow(jy[0,:,:,0])</div></div><!-- fragment --><p>They looks the same. How about the performance? </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;%time y = conv_naive(x, w)</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;%time jy = conv(jx, jw).fetch_sync()</div></div><!-- fragment --><p>The jittor implementation is much faster. So why this two implementation are equivalent in math, and why jittor's implementation is faster? We will explain step by step:</p>
<p>First, let's take a look at the help document of <code>jt.reindex</code></p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;help(jt.reindex)</div></div><!-- fragment --><p>Following the document, we can expand the reindex operation for better understanding:</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;py</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;xx = x.reindex([N,H-Kh+1,W-Kw+1,Kh,Kw,C,Kc], [</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;    &#39;i0&#39;, # Nid</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;    &#39;i1+i3&#39;, # Hid+Khid</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;    &#39;i2+i4&#39;, # Wid+KWid</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;    &#39;i5&#39;, # Cid</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;])</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;ww = w.broadcast_var(xx)</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;yy = xx*ww</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;y = yy.sum([3,4,5]) # Kh, Kw, Kc</div></div><!-- fragment --><p><b>After expansion:</b></p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;py</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;shape = [N,H+Kh-1,W+Kw-1,Kh,Kw,C,Kc]</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;# expansion of x.reindex</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;xx = np.zeros(shape, x.dtype)</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;for i0 in range(shape[0]):</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;    for i1 in range(shape[1]):</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;        for i2 in range(shape[2]):</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;            for i3 in range(shape[3]):</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;                for i4 in range(shape[4]):</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;                    for i5 in range(shape[5]):</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;                        for i6 in range(shape[6]):</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;                            if is_overflow(i0,i1,i2,i3,i4,i5,i6):</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;                                y[i0,i1,...,in] = 0</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;                            else:</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;                                y[i0,i1,i2,i3,i4,i5,i6] = x[i0,i1+i3,i2+i4,i5]</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;# expansion of w.broadcast_var(xx)</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;ww = np.zeros(shape, x.dtype)</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;for i0 in range(shape[0]):</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;    for i1 in range(shape[1]):</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;        for i2 in range(shape[2]):</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;            for i3 in range(shape[3]):</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;                for i4 in range(shape[4]):</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;                    for i5 in range(shape[5]):</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;                        for i6 in range(shape[6]):</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;                            ww[i0,i1,i2,i3,i4,i5,i6] = w[i3,i4,i5,i6]</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;# expansion of xx*ww</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;yy = np.zeros(shape, x.dtype)</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;for i0 in range(shape[0]):</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;    for i1 in range(shape[1]):</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;        for i2 in range(shape[2]):</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;            for i3 in range(shape[3]):</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;                for i4 in range(shape[4]):</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;                    for i5 in range(shape[5]):</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;                        for i6 in range(shape[6]):</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;                            yy[i0,i1,i2,i3,i4,i5,i6] = xx[i0,i1,i2,i3,i4,i5,i6] * ww[i0,i1,i2,i3,i4,i5,i6]</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;# expansion of yy.sum([3,4,5])</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;shape2 = [N,H-Kh+1,W-Kw+1,Kc]</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;y = np.zeros(shape2, x.dtype)</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;for i0 in range(shape[0]):</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;    for i1 in range(shape[1]):</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;        for i2 in range(shape[2]):</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;            for i3 in range(shape[3]):</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;                for i4 in range(shape[4]):</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;                    for i5 in range(shape[5]):</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;                        for i6 in range(shape[6]):</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;                            y[i0,i1,i2,i6] += yy[i0,i1,i2,i3,i4,i5,i6]</div></div><!-- fragment --><p><b>After loop fusion:</b></p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;py</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;shape2 = [N,H-Kh+1,W-Kw+1,Kc]</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;y = np.zeros(shape2, x.dtype)</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;for i0 in range(shape[0]):</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;    for i1 in range(shape[1]):</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;        for i2 in range(shape[2]):</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;            for i3 in range(shape[3]):</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;                for i4 in range(shape[4]):</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;                    for i5 in range(shape[5]):</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;                        for i6 in range(shape[6]):</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;                            if not is_overflow(i0,i1,i2,i3,i4,i5,i6):</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;                                y[i0,i1,i2,i6] += x[i0,i1+i3,i2+i4,i5]</div></div><!-- fragment --><p>This is the trick of meta-operator, It can fused multiple operator into a complicated operation, including many variation of convolution (e.g. group conv, seperate conv,...).</p>
<p>jittor will try to optimize the fused operation as fast as possible. Let's try some optimizations(compile the shapes as constants into the kernel), and show the underlying c++ kernel.</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;jt.flags.compile_options={&quot;compile_shapes&quot;:1}</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;with jt.profile_scope() as report:</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;    jy = conv(jx, jw).fetch_sync()</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;jt.flags.compile_options={}</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;print(f&quot;Time: {float(report[1][4])/1e6}ms&quot;)</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;with open(report[1][1], &#39;r&#39;) as f:</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;    print(f.read())</div></div><!-- fragment --><p>Even faster than the previous implementation! Because the compiler knows the shapes of the kernel and more optimizations are used. Take a look at function definition of <code>func0</code>, this is the main code of our convolution kernel. And this kernel is generated Just-in-time. </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
